{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/author-id-network/blob/master/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOdWuCQNoNv",
        "colab_type": "text"
      },
      "source": [
        "# **Author Identification**\n",
        "#### Eric Burdett\n",
        "\n",
        "This notebook contains code that can successfully identify authors given a page of handwritten text. The datasets used come from the Missionary Journals dataset that is made available from the BYU library. This work is based off of the following papers:\n",
        "\n",
        "*   Paper #1\n",
        "*   Paper #2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmQvEN8qCD2",
        "colab_type": "text"
      },
      "source": [
        "##Install PyTorch and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgvRdcMpTUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "caf1b837-ee89-4132-ba37-27a08ffdfb9c"
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgyBKjilpXsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HigOWkfRqRuJ",
        "colab_type": "text"
      },
      "source": [
        "##Import & Create Missionary Journal Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIGyUuMAqbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MissionaryDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __get__item(self, index):\n",
        "    pass\n",
        "\n",
        "  def __len__(self):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoyVcM3Uqsjn",
        "colab_type": "text"
      },
      "source": [
        "##Create our model using a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJAHFVsbrBcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepWriterNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(DeepWriterNetwork, self).__init__()\n",
        "\n",
        "    x, y = dataset[0]\n",
        "    in_channels, height, width = x.size()\n",
        "\n",
        "    num_classes = 10 # Get this value from the dataset or as a parameter\n",
        "\n",
        "    CONV1_CHANNELS = 96\n",
        "    CONV1_SIZE = (5, 5)\n",
        "    CONV1_STRIDE = 2 \n",
        "    CONV1_PADDING = 0\n",
        "    CONV2_5_CHANNELS = 256\n",
        "    CONV2_5_SIZE = (3, 3)\n",
        "    CONV2_5_STRIDE = 1\n",
        "    CONV2_5_PADDING = 1\n",
        "    CONV3_4_CHANNELS = 384\n",
        "    CONV3_4_SIZE = (3, 3)\n",
        "    CONV3_4_STRIDE = 1\n",
        "    CONV3_4_PADDING = 1\n",
        "    FC_COUNT = 1024\n",
        "\n",
        "    MP_SIZE= (3, 3)\n",
        "    MP_STRIDE = 2\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, CONV1_CHANNELS, CONV1_SIZE, stride=CONV1_STRIDE, padding=CONV1_PADDING),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE),\n",
        "      nn.Conv2d(CONV1_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE),\n",
        "      nn.Conv2d(CONV2_5_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(CONV3_4_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(CONV3_4_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE),\n",
        "      nn.Linear(FC_COUNT, FC_COUNT, bias=True),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(FC_COUNT, FC_COUNT, bias=True),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(p=0.5), # should this be inplace=True or inplace=False?\n",
        "      nn.Linear(FC_COUNT, num_classes), # Is this how we narrow it down to the number of classes?\n",
        "      nn.Softmax2d() # Is this the correct way to do the softmax at the end?\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl7tVR2ErV7M",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_NcVwOrdVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  train()\n",
        "  gc.collect()\n",
        "except:\n",
        "  gc.collect()\n",
        "  __ITB__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYdYGziroaq",
        "colab_type": "text"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdkwEMkFrv_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Data\n",
        "# What accuracy do we achieve?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ltr9lNr2ag",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGLEzUYIr77s",
        "colab_type": "text"
      },
      "source": [
        "The above CNN architecture achieves...\n",
        "\n",
        "These are the contributions and performance of the model..."
      ]
    }
  ]
}