{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/author-id-network/blob/master/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOdWuCQNoNv",
        "colab_type": "text"
      },
      "source": [
        "# **Author Identification**\n",
        "#### Eric Burdett\n",
        "\n",
        "This notebook contains code that can successfully identify authors given a page of handwritten text. The datasets used come from the Missionary Journals dataset that is made available from the BYU library. This work is based off of the following papers:\n",
        "\n",
        "*   Paper #1\n",
        "*   Paper #2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmQvEN8qCD2",
        "colab_type": "text"
      },
      "source": [
        "##Install PyTorch and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgvRdcMpTUY",
        "colab_type": "code",
        "outputId": "caf1b837-ee89-4132-ba37-27a08ffdfb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgyBKjilpXsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ef802f7f-fa01-43cd-f8c0-d7cd131e8141"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "import pdb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HigOWkfRqRuJ",
        "colab_type": "text"
      },
      "source": [
        "##Import & Create Missionary Journal Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIMmLHE0P7zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the dataset over to colab\n",
        "!cp \"drive/My Drive/datasets/missionary.tar.gz\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3MhFQ3PmZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract into /content/missionary\n",
        "!tar xzf missionary.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIGyUuMAqbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MissionaryDataset(Dataset):\n",
        "  def __init__(self, size=128):\n",
        "    if not os.path.exists('/content/missionary'):\n",
        "      raise Exception('Missionary dataset does not exist in /content/missionary')\n",
        "\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder('/content/missionary',\n",
        "        transform=transforms.Compose([transforms.Resize(size), transforms.ToTensor()]))\n",
        "\n",
        "  def num_classes(self):\n",
        "    return len(self.dataset_folder.class_to_idx)\n",
        "\n",
        "  def idx_to_class(self, idx):\n",
        "    for key, value in self.dataset_folder.class_to_idx.items():\n",
        "      if value == idx:\n",
        "        return key\n",
        "    \n",
        "    raise Exception('Class not found for index ' + idx)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.dataset_folder[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoyVcM3Uqsjn",
        "colab_type": "text"
      },
      "source": [
        "##Create our model using a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJAHFVsbrBcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AuthorIdNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(AuthorIdNetwork, self).__init__()\n",
        "\n",
        "    x, y = dataset[0]\n",
        "    in_channels, height, width = x.size()\n",
        "\n",
        "    num_classes = dataset.num_classes()\n",
        "\n",
        "    CONV1_CHANNELS = 96\n",
        "    CONV1_SIZE = (5, 5)\n",
        "    CONV1_STRIDE = 1\n",
        "    CONV1_PADDING = 2\n",
        "    CONV2_5_CHANNELS = 256 \n",
        "    CONV2_5_SIZE = (3, 3)\n",
        "    CONV2_5_STRIDE = 1\n",
        "    CONV2_5_PADDING = 1\n",
        "    CONV3_4_CHANNELS = 384\n",
        "    CONV3_4_SIZE = (3, 3)\n",
        "    CONV3_4_STRIDE = 1\n",
        "    CONV3_4_PADDING = 1\n",
        "    FC_COUNT = 1024\n",
        "    self.fc_input = CONV2_5_CHANNELS * (height // 8) * (width // 8)\n",
        "\n",
        "    MP_SIZE= (3, 3)\n",
        "    MP_STRIDE = 2\n",
        "    MP_PADDING = 1\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels, CONV1_CHANNELS, CONV1_SIZE, stride=CONV1_STRIDE, padding=CONV1_PADDING)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.mp1 = nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE, padding=MP_PADDING)\n",
        "    self.conv2 = nn.Conv2d(CONV1_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.mp2 =  nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE, padding=MP_PADDING)\n",
        "    self.conv3 = nn.Conv2d(CONV2_5_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.conv4 = nn.Conv2d(CONV3_4_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING)\n",
        "    self.relu4 = nn.ReLU()\n",
        "    self.conv5 = nn.Conv2d(CONV3_4_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING)\n",
        "    self.relu5 = nn.ReLU()\n",
        "    self.mp3 = nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE, padding=MP_PADDING)\n",
        "    self.fc1 = nn.Linear(self.fc_input, FC_COUNT, bias=True)\n",
        "    self.relu6 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(FC_COUNT, num_classes, bias=True)\n",
        "    self.relu7 = nn.ReLU()\n",
        "    self.drop = nn.Dropout(p=0.5)\n",
        "    self.soft = nn.Softmax(dim=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "\n",
        "    conv1_out = self.conv1(x)\n",
        "    # print('conv1_out:', conv1_out.shape)\n",
        "    relu1_out = self.relu1(conv1_out)\n",
        "    mp1_out = self.mp1(relu1_out)\n",
        "    # print('mp1_out:', mp1_out.shape)\n",
        "    conv2_out = self.conv2(mp1_out)\n",
        "    # print('conv2_out:', conv2_out.shape)\n",
        "    relu2_out = self.relu2(conv2_out)\n",
        "    mp2_out = self.mp2(relu2_out)\n",
        "    # print('mp2_out:', mp2_out.shape)\n",
        "    conv3_out = self.conv3(mp2_out)\n",
        "    # print('conv3_out:', conv3_out.shape)\n",
        "    relu3_out = self.relu3(conv3_out)\n",
        "    conv4_out = self.conv4(relu3_out)\n",
        "    # print('conv4_out:', conv4_out.shape)\n",
        "    relu4_out = self.relu4(conv4_out)\n",
        "    conv5_out = self.conv5(relu4_out)\n",
        "    # print('conv5_out:', conv5_out.shape)\n",
        "    relu5_out = self.relu5(conv5_out)\n",
        "    mp3_out = self.mp3(relu5_out)\n",
        "    # print('mp3_out:', mp3_out.shape)\n",
        "    mp3_out_viewed = mp3_out.view(batch_size, self.fc_input)\n",
        "    fc1_out = self.fc1(mp3_out_viewed)\n",
        "    # print('fc1_out:', fc1_out.shape)\n",
        "    relu6_out = self.relu6(fc1_out)\n",
        "    fc2_out = self.fc2(relu6_out)\n",
        "    # print('fc2_out:', fc2_out.shape)\n",
        "    relu7_out = self.relu7(fc2_out)\n",
        "    drop_out = self.drop(relu7_out)\n",
        "    # print('drop_out:', drop_out.shape)\n",
        "    soft_out = self.soft(drop_out)\n",
        "    # print('soft_out:', soft_out.shape)\n",
        "\n",
        "    return soft_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl7tVR2ErV7M",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_NcVwOrdVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4f1a935-7307-4c22-f6c6-edd50c06ae5c"
      },
      "source": [
        "def train():\n",
        "  NUM_EPOCHS = 1\n",
        "  BATCH_SIZE = 2\n",
        "\n",
        "  dataset = MissionaryDataset()\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(.8 * len(dataset)), int(.2 * len(dataset))])\n",
        "\n",
        "  model = AuthorIdNetwork(dataset)\n",
        "  model = model.cuda()\n",
        "\n",
        "  objective = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            num_workers=2,\n",
        "                            pin_memory=True,\n",
        "                            shuffle=True)\n",
        "  \n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=2,\n",
        "                          pin_memory=True,\n",
        "                          shuffle=True)\n",
        "  \n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  train_accs = []\n",
        "  val_accs = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "\n",
        "    for batch, (x, y_truth) in enumerate(train_loader):\n",
        "      gc.collect()\n",
        "      x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_hat = model(x)\n",
        "\n",
        "      accuracy = torch.eq(y_hat.argmax(1), y_truth.long()).float().mean()\n",
        "      loss = objective(y_hat, y_truth.long())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "      train_accs.append(accuracy.item())\n",
        "\n",
        "      loop.set_description('epoch:{}, loss:{:.4f}, accuracy:{:.4f}'.format(epoch, loss.item(), accuracy.item()))\n",
        "      loop.update(1)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 10 == 0:\n",
        "        gc.collect()\n",
        "\n",
        "        val_single_acc = []\n",
        "        val_single_loss = []\n",
        "\n",
        "        for val_x, val_y_truth in val_loader:\n",
        "          gc.collect()\n",
        "          val_x, val_y_truth = val_x.cuda(), val_y_truth.cuda().long()\n",
        "\n",
        "          val_y_hat = model(val_x)\n",
        "\n",
        "          val_accuracy = torch.eq(val_y_hat.argmax(), val_y_truth)\n",
        "          val_loss = objective(val_y_hat, val_y_truth)\n",
        "\n",
        "          val_single_acc.append(val_accuracy)\n",
        "          val_single_loss.append(val_loss)\n",
        "\n",
        "        val_accs.append(val_single_acc)\n",
        "        val_losses.append(val_single_loss)\n",
        "    \n",
        "    loop.close()\n",
        "\n",
        "  return model, train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "try:\n",
        "  model, train_losses, val_losses, train_accs, val_accs = train()\n",
        "  gc.collect()\n",
        "except:\n",
        "  gc.collect()\n",
        "  __ITB__()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0, loss:4.0053, accuracy:0.0000:   0%|          | 1/6132 [00:00<18:18,  5.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-7-53956a70de2a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m     62\u001b[0m           \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 64\u001b[0;31m           \u001b[0mval_y_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mval_y_hat\u001b[0m \u001b[0;34m= tensor([[5.0000e-01, 5.0000e-01, 5.0000e-01, 4.9872e-01, 5.0000e-01, 1.9347e-02,\n",
            "         5.0000e-01, 5.0000e-01, 1.1775e-01, 1.8684e-01, 5.0000e-01, 5.0000e-01,\n",
            "         4.8647e-01, 5.0000e-01, 1.1406e-01, 5.0000e-01, 5.0000e-01, 4.9484e-01,\n",
            "         5.0000e-01, 9.4990e-01, 5.0000e-01, 4.9192e-01, 4.9886e-01, 4.9647e-01,\n",
            "         7.3376e-01, 1.4636e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 8.3357e-04,\n",
            "         5.0000e-01, 5.0000e-01, 4.9815e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
            "         5.0000e-01, 5.0796e-01, 5.0000e-01, 5.0000e-01, 7.7675e-01, 5.0000e-01,\n",
            "         5.0000e-01, 7.1601e-01, 4.8780e-01, 5.0000e-01, 5.0000e-01, 1.3574e-01,\n",
            "         5.0000e-01, 2.0539e-01, 8.9136e-05, 5.0000e-01, 5.0000e-01, 1.0449e-27,\n",
            "         5.0000e-01],\n",
            "        [5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0128e-01, 5.0000e-01, 9.8065e-01,\n",
            "         5.0000e-01, 5.0000e-01, 8.8225e-01, 8.1316e-01, 5.0000e-01, 5.0000e-01,\n",
            "         5.1353e-01, 5.0000e-01, 8.8594e-01, 5.0000e-01, 5.0000e-01, 5.0516e-01,\n",
            "         5.0000e-01, 5.0104e-02, 5.0000e-01, 5.0808e-01, 5.0114e-01, 5.0353e-01,\n",
            "         2.6624e-01, 8.5364e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 9.9917e-01,\n",
            "         5.0000e-01, 5.0000e-01, 5.0185e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
            "         5.0000e-01, 4.9204e-01, 5.0000e-01, 5.0000e-01, 2.2325e-01, 5.0000e-01,\n",
            "         5.0000e-01, 2.8399e-01, 5.1220e-01, 5.0000e-01, 5.0000e-01, 8.6426e-01,\n",
            "         5.0000e-01, 7.9461e-01, 9.9991e-01, 5.0000e-01, 5.0000e-01, 1.0000e+00,\n",
            "         5.0000e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mmodel\u001b[0m \u001b[0;34m= AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (mp1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (mp2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu4): ReLU()\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu5): ReLU()\n",
            "  (mp3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=65536, out_features=1024, bias=True)\n",
            "  (relu6): ReLU()\n",
            "  (fc2): Linear(in_features=1024, out_features=55, bias=True)\n",
            "  (relu7): ReLU()\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            ")\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mval_x\u001b[0m \u001b[0;34m= tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          ...,\n",
            "          [0.2353, 0.3922, 0.6706,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.1804, 0.6549, 0.9804,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.8745, 0.9804, 1.0000,  ..., 1.0000, 0.9961, 0.8157]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          ...,\n",
            "          [0.2353, 0.3922, 0.6706,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.1804, 0.6549, 0.9804,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.8745, 0.9804, 1.0000,  ..., 1.0000, 0.9961, 0.8157]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          ...,\n",
            "          [0.2353, 0.3922, 0.6706,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.1804, 0.6549, 0.9804,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.8745, 0.9804, 1.0000,  ..., 1.0000, 0.9961, 0.8157]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.3686],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.7529, 0.3961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9451],\n",
            "          ...,\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.6863, 0.9961, 0.9961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.9961, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 0.9961, 1.0000]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.3686],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.7529, 0.3961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9451],\n",
            "          ...,\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.6863, 0.9961, 0.9961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.9961, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 0.9961, 1.0000]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.3686],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.7529, 0.3961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9451],\n",
            "          ...,\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.6863, 0.9961, 0.9961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.9961, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 0.9961, 1.0000]]]],\n",
            "       device='cuda:0')\u001b[0m\n",
            "\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     66\u001b[0m           \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel...(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            "), *input=(tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000,...9804, 0.9961, 1.0000]]]],\n",
            "       device='cuda:0'),), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.forward\u001b[0m \u001b[0;34m= <bound method AuthorIdNetwork.forward of AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (mp1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (mp2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu4): ReLU()\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu5): ReLU()\n",
            "  (mp3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=65536, out_features=1024, bias=True)\n",
            "  (relu6): ReLU()\n",
            "  (fc2): Linear(in_features=1024, out_features=55, bias=True)\n",
            "  (relu7): ReLU()\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            ")>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= (tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          ...,\n",
            "          [0.2353, 0.3922, 0.6706,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.1804, 0.6549, 0.9804,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.8745, 0.9804, 1.0000,  ..., 1.0000, 0.9961, 0.8157]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          ...,\n",
            "          [0.2353, 0.3922, 0.6706,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.1804, 0.6549, 0.9804,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.8745, 0.9804, 1.0000,  ..., 1.0000, 0.9961, 0.8157]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "          ...,\n",
            "          [0.2353, 0.3922, 0.6706,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.1804, 0.6549, 0.9804,  ..., 0.9961, 0.9961, 0.9961],\n",
            "          [0.8745, 0.9804, 1.0000,  ..., 1.0000, 0.9961, 0.8157]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.3686],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.7529, 0.3961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9451],\n",
            "          ...,\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.6863, 0.9961, 0.9961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.9961, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 0.9961, 1.0000]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.3686],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.7529, 0.3961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9451],\n",
            "          ...,\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.6863, 0.9961, 0.9961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.9961, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 0.9961, 1.0000]],\n",
            "\n",
            "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.5020, 0.3686],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.7529, 0.3961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9451],\n",
            "          ...,\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.6863, 0.9961, 0.9961],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.9961, 1.0000],\n",
            "          [1.0000, 1.0000, 1.0000,  ..., 0.9804, 0.9961, 1.0000]]]],\n",
            "       device='cuda:0'),)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m<ipython-input-5-c0ac9f31007d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self=AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel...(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            "), x=tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000,...9804, 0.9961, 1.0000]]]],\n",
            "       device='cuda:0'))\u001b[0m\n",
            "\u001b[1;32m     57\u001b[0m     \u001b[0mconv2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp1_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     58\u001b[0m     \u001b[0;31m# print('conv2_out:', conv2_out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mrelu2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mrelu2_out\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.relu2\u001b[0m \u001b[0;34m= ReLU()\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mconv2_out\u001b[0m \u001b[0;34m= tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01,  ...,  5.2667e-01,\n",
            "            5.5237e-01,  4.6490e-01],\n",
            "          [ 3.2353e-01,  6.8259e-01,  7.8043e-01,  ...,  6.8623e-01,\n",
            "            6.8309e-01,  6.8942e-01],\n",
            "          [ 3.0407e-01,  7.1957e-01,  8.8579e-01,  ...,  7.1020e-01,\n",
            "            7.0813e-01,  7.1430e-01],\n",
            "          ...,\n",
            "          [ 3.8517e-01,  7.7096e-01,  8.5553e-01,  ...,  8.4784e-01,\n",
            "            8.8967e-01,  8.5234e-01],\n",
            "          [ 3.4952e-01,  7.5828e-01,  9.1787e-01,  ...,  8.3961e-01,\n",
            "            9.5525e-01,  8.5680e-01],\n",
            "          [ 8.4299e-02,  3.4485e-01,  4.2244e-01,  ...,  3.3204e-01,\n",
            "            4.3116e-01,  4.7426e-01]],\n",
            "\n",
            "         [[-1.6261e-01, -7.5415e-02,  8.9645e-03,  ..., -2.0193e-02,\n",
            "            2.7943e-04, -1.7276e-03],\n",
            "          [-6.3013e-02, -1.2413e-02,  7.7958e-02,  ...,  8.0224e-02,\n",
            "            1.2833e-01,  6.6621e-02],\n",
            "          [-4.8644e-02,  9.5492e-02,  2.3655e-01,  ...,  2.2618e-01,\n",
            "            2.7108e-01,  1.6030e-01],\n",
            "          ...,\n",
            "          [-3.8225e-02,  2.3628e-01,  2.8129e-01,  ...,  1.5612e-01,\n",
            "            1.6205e-01,  1.6639e-01],\n",
            "          [ 8.2544e-03,  1.7176e-01,  2.2643e-01,  ...,  1.0285e-01,\n",
            "            2.3193e-01,  2.1735e-01],\n",
            "          [-4.5093e-02,  6.6791e-02,  8.0809e-02,  ...,  1.0619e-01,\n",
            "            4.5429e-02,  6.7398e-02]],\n",
            "\n",
            "         [[-1.7757e-01, -6.6883e-02, -1.2870e-01,  ..., -1.2277e-01,\n",
            "           -8.6087e-02, -4.9190e-02],\n",
            "          [-2.2887e-01, -4.9538e-03, -1.6677e-02,  ..., -7.4911e-02,\n",
            "           -4.7620e-02,  1.2085e-02],\n",
            "          [-1.7611e-01,  6.9240e-02,  3.3180e-02,  ..., -2.5870e-02,\n",
            "            5.3273e-03,  1.8564e-02],\n",
            "          ...,\n",
            "          [-2.3840e-01,  1.1302e-01,  1.0345e-01,  ...,  7.6853e-02,\n",
            "            7.7509e-02,  1.0883e-01],\n",
            "          [-2.8322e-01, -3.9816e-02, -2.9238e-02,  ...,  5.8792e-03,\n",
            "            5.7806e-03,  6.0865e-02],\n",
            "          [-1.8434e-02,  1.4488e-01,  2.8176e-01,  ...,  2.2517e-01,\n",
            "            2.4294e-01,  2.5818e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7776e-02,  2.7535e-01,  2.2139e-01,  ...,  1.4856e-01,\n",
            "            1.3826e-01,  1.6213e-01],\n",
            "          [ 9.0671e-02,  1.2583e-01,  4.7118e-02,  ..., -1.2368e-03,\n",
            "            3.4674e-02,  3.8269e-02],\n",
            "          [ 5.7875e-02, -3.2173e-02, -3.6749e-02,  ..., -4.1819e-02,\n",
            "           -2.2558e-02,  5.5626e-05],\n",
            "          ...,\n",
            "          [ 6.9382e-03,  2.0947e-02, -4.9817e-03,  ...,  2.9012e-03,\n",
            "            2.1494e-02,  1.0317e-01],\n",
            "          [ 5.4558e-02,  9.8283e-02, -7.0156e-04,  ...,  2.7193e-02,\n",
            "            1.1683e-01,  1.2481e-01],\n",
            "          [-6.6755e-02, -1.4735e-01, -2.2934e-01,  ..., -1.9050e-01,\n",
            "           -6.0468e-02, -3.2745e-02]],\n",
            "\n",
            "         [[-8.9371e-02,  1.1433e-02, -1.7514e-02,  ..., -2.4120e-02,\n",
            "            6.1822e-02, -1.3374e-01],\n",
            "          [ 1.7685e-01,  2.3977e-01,  2.5490e-01,  ...,  2.3110e-01,\n",
            "            3.3218e-01, -5.5621e-02],\n",
            "          [ 3.4207e-01,  3.4190e-01,  4.1957e-01,  ...,  3.5915e-01,\n",
            "            4.6486e-01,  3.2820e-02],\n",
            "          ...,\n",
            "          [ 3.3726e-01,  3.7194e-01,  3.2754e-01,  ...,  3.3786e-01,\n",
            "            4.0417e-01,  1.6520e-02],\n",
            "          [ 3.0273e-01,  3.7899e-01,  3.0671e-01,  ...,  3.3068e-01,\n",
            "            4.6788e-01,  1.2872e-02],\n",
            "          [ 3.2531e-01,  2.8950e-01,  2.5689e-01,  ...,  3.1262e-01,\n",
            "            3.0557e-01, -4.5271e-02]],\n",
            "\n",
            "         [[-1.4164e-01, -9.9954e-02, -2.0803e-01,  ..., -1.6111e-01,\n",
            "           -1.8806e-01, -1.6816e-02],\n",
            "          [-1.2879e-01, -7.2904e-02, -1.2950e-01,  ..., -8.4548e-02,\n",
            "           -1.2626e-01, -9.2979e-02],\n",
            "          [-8.1983e-02, -4.6783e-02, -5.9240e-02,  ..., -6.6736e-03,\n",
            "           -9.0917e-02, -7.3542e-02],\n",
            "          ...,\n",
            "          [-1.0109e-01, -1.8327e-02,  1.9710e-02,  ...,  5.8757e-02,\n",
            "           -3.7721e-02,  1.4710e-03],\n",
            "          [-7.0754e-02, -5.0375e-02, -8.8741e-02,  ...,  9.0158e-02,\n",
            "            2.3188e-02, -1.2490e-02],\n",
            "          [ 1.4627e-02,  3.4848e-02,  9.1501e-02,  ...,  1.0077e-01,\n",
            "            8.5178e-02,  9.2107e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1936e-01,  4.8755e-01,  5.3338e-01,  ...,  5.4434e-01,\n",
            "            5.6995e-01,  4.5253e-01],\n",
            "          [ 3.2122e-01,  6.3739e-01,  6.8355e-01,  ...,  6.6625e-01,\n",
            "            7.2255e-01,  6.8929e-01],\n",
            "          [ 3.1748e-01,  6.5308e-01,  7.1021e-01,  ...,  6.8244e-01,\n",
            "            7.1051e-01,  7.4026e-01],\n",
            "          ...,\n",
            "          [ 3.5199e-01,  6.7922e-01,  7.2209e-01,  ...,  7.9005e-01,\n",
            "            8.5600e-01,  8.3584e-01],\n",
            "          [ 3.9327e-01,  7.4837e-01,  7.9135e-01,  ...,  8.3054e-01,\n",
            "            8.6740e-01,  8.2597e-01],\n",
            "          [ 7.4166e-02,  3.0505e-01,  3.4141e-01,  ...,  3.3958e-01,\n",
            "            4.0208e-01,  4.5727e-01]],\n",
            "\n",
            "         [[-1.6369e-01, -9.1060e-02,  5.3837e-03,  ..., -1.7801e-02,\n",
            "            5.3160e-03, -1.0549e-02],\n",
            "          [-1.0814e-01, -7.1165e-03,  1.1115e-01,  ...,  8.2625e-02,\n",
            "            1.1213e-01,  7.4539e-02],\n",
            "          [-2.7054e-02,  1.3876e-01,  2.8103e-01,  ...,  2.4338e-01,\n",
            "            2.5727e-01,  1.6102e-01],\n",
            "          ...,\n",
            "          [-2.9401e-02,  9.8652e-02,  2.2603e-01,  ...,  2.2084e-01,\n",
            "            1.8632e-01,  1.8653e-01],\n",
            "          [-1.9563e-02,  9.1123e-02,  2.0794e-01,  ...,  1.5052e-01,\n",
            "            1.5083e-01,  1.5547e-01],\n",
            "          [-7.0914e-02, -1.5331e-02,  7.0039e-02,  ...,  8.2683e-02,\n",
            "            6.0083e-02,  8.3643e-02]],\n",
            "\n",
            "         [[-1.7497e-01, -5.3898e-02, -1.0758e-01,  ..., -1.2381e-01,\n",
            "           -9.0082e-02, -4.7127e-02],\n",
            "          [-2.2501e-01,  4.1229e-03, -3.9401e-02,  ..., -6.1151e-02,\n",
            "           -3.2936e-02, -2.1774e-02],\n",
            "          [-2.7936e-01,  1.7223e-02, -2.2377e-02,  ..., -1.9218e-02,\n",
            "            3.0732e-02,  1.6587e-02],\n",
            "          ...,\n",
            "          [-2.6118e-01,  2.4114e-02,  4.9451e-03,  ...,  4.1661e-02,\n",
            "            6.0266e-02,  1.0456e-01],\n",
            "          [-3.1828e-01, -4.3081e-02, -5.6697e-02,  ...,  1.5097e-02,\n",
            "            1.2163e-02,  9.7990e-02],\n",
            "          [ 1.2590e-02,  2.9730e-01,  3.2151e-01,  ...,  3.2187e-01,\n",
            "            2.2438e-01,  1.5837e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9638e-02,  2.3557e-01,  1.8097e-01,  ...,  1.4664e-01,\n",
            "            1.4341e-01,  1.1406e-01],\n",
            "          [ 3.9965e-02,  5.4214e-02,  1.1951e-02,  ..., -1.1070e-03,\n",
            "            3.1058e-02,  1.8292e-02],\n",
            "          [-5.5255e-03, -1.5887e-02, -4.7001e-02,  ..., -5.9117e-02,\n",
            "           -1.9441e-02,  2.0055e-04],\n",
            "          ...,\n",
            "          [ 2.1075e-04, -1.3586e-02, -5.8728e-02,  ..., -2.1825e-02,\n",
            "            1.6546e-03,  6.4870e-02],\n",
            "          [ 6.1808e-02,  6.3894e-02,  8.7541e-05,  ...,  2.9056e-02,\n",
            "            6.2418e-02,  1.1499e-01],\n",
            "          [-2.9677e-03, -1.5113e-01, -1.9361e-01,  ..., -1.7929e-01,\n",
            "           -9.4297e-02, -1.2342e-02]],\n",
            "\n",
            "         [[-9.8626e-02,  8.9007e-03, -7.0347e-03,  ..., -1.7574e-04,\n",
            "            2.3958e-02, -1.3545e-01],\n",
            "          [ 1.6619e-01,  2.5718e-01,  2.6824e-01,  ...,  2.2335e-01,\n",
            "            2.8343e-01, -9.0829e-02],\n",
            "          [ 2.7654e-01,  3.6372e-01,  3.9330e-01,  ...,  3.5126e-01,\n",
            "            4.3444e-01,  5.7304e-03],\n",
            "          ...,\n",
            "          [ 2.4019e-01,  3.0182e-01,  3.3140e-01,  ...,  3.6036e-01,\n",
            "            4.4168e-01,  2.0328e-02],\n",
            "          [ 2.3956e-01,  3.3566e-01,  3.5492e-01,  ...,  3.5695e-01,\n",
            "            4.2771e-01,  2.8168e-02],\n",
            "          [ 3.5225e-01,  3.3300e-01,  3.0612e-01,  ...,  2.4498e-01,\n",
            "            3.3060e-01,  4.2823e-03]],\n",
            "\n",
            "         [[-1.4233e-01, -1.1079e-01, -1.8388e-01,  ..., -1.6999e-01,\n",
            "           -1.6591e-01, -2.9386e-02],\n",
            "          [-1.4843e-01, -8.5695e-02, -1.2984e-01,  ..., -1.1390e-01,\n",
            "           -1.5642e-01, -8.3582e-02],\n",
            "          [-1.2862e-01, -7.0163e-02, -8.2409e-02,  ..., -4.1030e-02,\n",
            "           -1.1463e-01, -8.5673e-02],\n",
            "          ...,\n",
            "          [-1.3838e-01, -5.6336e-02, -6.0371e-02,  ...,  4.0759e-03,\n",
            "           -7.4124e-03,  3.1254e-02],\n",
            "          [-1.3245e-01, -1.8066e-02, -2.3995e-02,  ...,  6.3334e-02,\n",
            "            8.0102e-02,  1.0305e-01],\n",
            "          [-3.1302e-02,  6.3442e-02,  9.5612e-02,  ...,  2.0618e-01,\n",
            "            1.6517e-01,  7.7537e-02]]]], device='cuda:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>)\u001b[0m\n",
            "\u001b[1;32m     60\u001b[0m     \u001b[0mmp2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu2_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print('mp2_out:', mp2_out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=ReLU(), *input=(tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01...da:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>),), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.forward\u001b[0m \u001b[0;34m= <bound method ReLU.forward of ReLU()>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= (tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01,  ...,  5.2667e-01,\n",
            "            5.5237e-01,  4.6490e-01],\n",
            "          [ 3.2353e-01,  6.8259e-01,  7.8043e-01,  ...,  6.8623e-01,\n",
            "            6.8309e-01,  6.8942e-01],\n",
            "          [ 3.0407e-01,  7.1957e-01,  8.8579e-01,  ...,  7.1020e-01,\n",
            "            7.0813e-01,  7.1430e-01],\n",
            "          ...,\n",
            "          [ 3.8517e-01,  7.7096e-01,  8.5553e-01,  ...,  8.4784e-01,\n",
            "            8.8967e-01,  8.5234e-01],\n",
            "          [ 3.4952e-01,  7.5828e-01,  9.1787e-01,  ...,  8.3961e-01,\n",
            "            9.5525e-01,  8.5680e-01],\n",
            "          [ 8.4299e-02,  3.4485e-01,  4.2244e-01,  ...,  3.3204e-01,\n",
            "            4.3116e-01,  4.7426e-01]],\n",
            "\n",
            "         [[-1.6261e-01, -7.5415e-02,  8.9645e-03,  ..., -2.0193e-02,\n",
            "            2.7943e-04, -1.7276e-03],\n",
            "          [-6.3013e-02, -1.2413e-02,  7.7958e-02,  ...,  8.0224e-02,\n",
            "            1.2833e-01,  6.6621e-02],\n",
            "          [-4.8644e-02,  9.5492e-02,  2.3655e-01,  ...,  2.2618e-01,\n",
            "            2.7108e-01,  1.6030e-01],\n",
            "          ...,\n",
            "          [-3.8225e-02,  2.3628e-01,  2.8129e-01,  ...,  1.5612e-01,\n",
            "            1.6205e-01,  1.6639e-01],\n",
            "          [ 8.2544e-03,  1.7176e-01,  2.2643e-01,  ...,  1.0285e-01,\n",
            "            2.3193e-01,  2.1735e-01],\n",
            "          [-4.5093e-02,  6.6791e-02,  8.0809e-02,  ...,  1.0619e-01,\n",
            "            4.5429e-02,  6.7398e-02]],\n",
            "\n",
            "         [[-1.7757e-01, -6.6883e-02, -1.2870e-01,  ..., -1.2277e-01,\n",
            "           -8.6087e-02, -4.9190e-02],\n",
            "          [-2.2887e-01, -4.9538e-03, -1.6677e-02,  ..., -7.4911e-02,\n",
            "           -4.7620e-02,  1.2085e-02],\n",
            "          [-1.7611e-01,  6.9240e-02,  3.3180e-02,  ..., -2.5870e-02,\n",
            "            5.3273e-03,  1.8564e-02],\n",
            "          ...,\n",
            "          [-2.3840e-01,  1.1302e-01,  1.0345e-01,  ...,  7.6853e-02,\n",
            "            7.7509e-02,  1.0883e-01],\n",
            "          [-2.8322e-01, -3.9816e-02, -2.9238e-02,  ...,  5.8792e-03,\n",
            "            5.7806e-03,  6.0865e-02],\n",
            "          [-1.8434e-02,  1.4488e-01,  2.8176e-01,  ...,  2.2517e-01,\n",
            "            2.4294e-01,  2.5818e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7776e-02,  2.7535e-01,  2.2139e-01,  ...,  1.4856e-01,\n",
            "            1.3826e-01,  1.6213e-01],\n",
            "          [ 9.0671e-02,  1.2583e-01,  4.7118e-02,  ..., -1.2368e-03,\n",
            "            3.4674e-02,  3.8269e-02],\n",
            "          [ 5.7875e-02, -3.2173e-02, -3.6749e-02,  ..., -4.1819e-02,\n",
            "           -2.2558e-02,  5.5626e-05],\n",
            "          ...,\n",
            "          [ 6.9382e-03,  2.0947e-02, -4.9817e-03,  ...,  2.9012e-03,\n",
            "            2.1494e-02,  1.0317e-01],\n",
            "          [ 5.4558e-02,  9.8283e-02, -7.0156e-04,  ...,  2.7193e-02,\n",
            "            1.1683e-01,  1.2481e-01],\n",
            "          [-6.6755e-02, -1.4735e-01, -2.2934e-01,  ..., -1.9050e-01,\n",
            "           -6.0468e-02, -3.2745e-02]],\n",
            "\n",
            "         [[-8.9371e-02,  1.1433e-02, -1.7514e-02,  ..., -2.4120e-02,\n",
            "            6.1822e-02, -1.3374e-01],\n",
            "          [ 1.7685e-01,  2.3977e-01,  2.5490e-01,  ...,  2.3110e-01,\n",
            "            3.3218e-01, -5.5621e-02],\n",
            "          [ 3.4207e-01,  3.4190e-01,  4.1957e-01,  ...,  3.5915e-01,\n",
            "            4.6486e-01,  3.2820e-02],\n",
            "          ...,\n",
            "          [ 3.3726e-01,  3.7194e-01,  3.2754e-01,  ...,  3.3786e-01,\n",
            "            4.0417e-01,  1.6520e-02],\n",
            "          [ 3.0273e-01,  3.7899e-01,  3.0671e-01,  ...,  3.3068e-01,\n",
            "            4.6788e-01,  1.2872e-02],\n",
            "          [ 3.2531e-01,  2.8950e-01,  2.5689e-01,  ...,  3.1262e-01,\n",
            "            3.0557e-01, -4.5271e-02]],\n",
            "\n",
            "         [[-1.4164e-01, -9.9954e-02, -2.0803e-01,  ..., -1.6111e-01,\n",
            "           -1.8806e-01, -1.6816e-02],\n",
            "          [-1.2879e-01, -7.2904e-02, -1.2950e-01,  ..., -8.4548e-02,\n",
            "           -1.2626e-01, -9.2979e-02],\n",
            "          [-8.1983e-02, -4.6783e-02, -5.9240e-02,  ..., -6.6736e-03,\n",
            "           -9.0917e-02, -7.3542e-02],\n",
            "          ...,\n",
            "          [-1.0109e-01, -1.8327e-02,  1.9710e-02,  ...,  5.8757e-02,\n",
            "           -3.7721e-02,  1.4710e-03],\n",
            "          [-7.0754e-02, -5.0375e-02, -8.8741e-02,  ...,  9.0158e-02,\n",
            "            2.3188e-02, -1.2490e-02],\n",
            "          [ 1.4627e-02,  3.4848e-02,  9.1501e-02,  ...,  1.0077e-01,\n",
            "            8.5178e-02,  9.2107e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1936e-01,  4.8755e-01,  5.3338e-01,  ...,  5.4434e-01,\n",
            "            5.6995e-01,  4.5253e-01],\n",
            "          [ 3.2122e-01,  6.3739e-01,  6.8355e-01,  ...,  6.6625e-01,\n",
            "            7.2255e-01,  6.8929e-01],\n",
            "          [ 3.1748e-01,  6.5308e-01,  7.1021e-01,  ...,  6.8244e-01,\n",
            "            7.1051e-01,  7.4026e-01],\n",
            "          ...,\n",
            "          [ 3.5199e-01,  6.7922e-01,  7.2209e-01,  ...,  7.9005e-01,\n",
            "            8.5600e-01,  8.3584e-01],\n",
            "          [ 3.9327e-01,  7.4837e-01,  7.9135e-01,  ...,  8.3054e-01,\n",
            "            8.6740e-01,  8.2597e-01],\n",
            "          [ 7.4166e-02,  3.0505e-01,  3.4141e-01,  ...,  3.3958e-01,\n",
            "            4.0208e-01,  4.5727e-01]],\n",
            "\n",
            "         [[-1.6369e-01, -9.1060e-02,  5.3837e-03,  ..., -1.7801e-02,\n",
            "            5.3160e-03, -1.0549e-02],\n",
            "          [-1.0814e-01, -7.1165e-03,  1.1115e-01,  ...,  8.2625e-02,\n",
            "            1.1213e-01,  7.4539e-02],\n",
            "          [-2.7054e-02,  1.3876e-01,  2.8103e-01,  ...,  2.4338e-01,\n",
            "            2.5727e-01,  1.6102e-01],\n",
            "          ...,\n",
            "          [-2.9401e-02,  9.8652e-02,  2.2603e-01,  ...,  2.2084e-01,\n",
            "            1.8632e-01,  1.8653e-01],\n",
            "          [-1.9563e-02,  9.1123e-02,  2.0794e-01,  ...,  1.5052e-01,\n",
            "            1.5083e-01,  1.5547e-01],\n",
            "          [-7.0914e-02, -1.5331e-02,  7.0039e-02,  ...,  8.2683e-02,\n",
            "            6.0083e-02,  8.3643e-02]],\n",
            "\n",
            "         [[-1.7497e-01, -5.3898e-02, -1.0758e-01,  ..., -1.2381e-01,\n",
            "           -9.0082e-02, -4.7127e-02],\n",
            "          [-2.2501e-01,  4.1229e-03, -3.9401e-02,  ..., -6.1151e-02,\n",
            "           -3.2936e-02, -2.1774e-02],\n",
            "          [-2.7936e-01,  1.7223e-02, -2.2377e-02,  ..., -1.9218e-02,\n",
            "            3.0732e-02,  1.6587e-02],\n",
            "          ...,\n",
            "          [-2.6118e-01,  2.4114e-02,  4.9451e-03,  ...,  4.1661e-02,\n",
            "            6.0266e-02,  1.0456e-01],\n",
            "          [-3.1828e-01, -4.3081e-02, -5.6697e-02,  ...,  1.5097e-02,\n",
            "            1.2163e-02,  9.7990e-02],\n",
            "          [ 1.2590e-02,  2.9730e-01,  3.2151e-01,  ...,  3.2187e-01,\n",
            "            2.2438e-01,  1.5837e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9638e-02,  2.3557e-01,  1.8097e-01,  ...,  1.4664e-01,\n",
            "            1.4341e-01,  1.1406e-01],\n",
            "          [ 3.9965e-02,  5.4214e-02,  1.1951e-02,  ..., -1.1070e-03,\n",
            "            3.1058e-02,  1.8292e-02],\n",
            "          [-5.5255e-03, -1.5887e-02, -4.7001e-02,  ..., -5.9117e-02,\n",
            "           -1.9441e-02,  2.0055e-04],\n",
            "          ...,\n",
            "          [ 2.1075e-04, -1.3586e-02, -5.8728e-02,  ..., -2.1825e-02,\n",
            "            1.6546e-03,  6.4870e-02],\n",
            "          [ 6.1808e-02,  6.3894e-02,  8.7541e-05,  ...,  2.9056e-02,\n",
            "            6.2418e-02,  1.1499e-01],\n",
            "          [-2.9677e-03, -1.5113e-01, -1.9361e-01,  ..., -1.7929e-01,\n",
            "           -9.4297e-02, -1.2342e-02]],\n",
            "\n",
            "         [[-9.8626e-02,  8.9007e-03, -7.0347e-03,  ..., -1.7574e-04,\n",
            "            2.3958e-02, -1.3545e-01],\n",
            "          [ 1.6619e-01,  2.5718e-01,  2.6824e-01,  ...,  2.2335e-01,\n",
            "            2.8343e-01, -9.0829e-02],\n",
            "          [ 2.7654e-01,  3.6372e-01,  3.9330e-01,  ...,  3.5126e-01,\n",
            "            4.3444e-01,  5.7304e-03],\n",
            "          ...,\n",
            "          [ 2.4019e-01,  3.0182e-01,  3.3140e-01,  ...,  3.6036e-01,\n",
            "            4.4168e-01,  2.0328e-02],\n",
            "          [ 2.3956e-01,  3.3566e-01,  3.5492e-01,  ...,  3.5695e-01,\n",
            "            4.2771e-01,  2.8168e-02],\n",
            "          [ 3.5225e-01,  3.3300e-01,  3.0612e-01,  ...,  2.4498e-01,\n",
            "            3.3060e-01,  4.2823e-03]],\n",
            "\n",
            "         [[-1.4233e-01, -1.1079e-01, -1.8388e-01,  ..., -1.6999e-01,\n",
            "           -1.6591e-01, -2.9386e-02],\n",
            "          [-1.4843e-01, -8.5695e-02, -1.2984e-01,  ..., -1.1390e-01,\n",
            "           -1.5642e-01, -8.3582e-02],\n",
            "          [-1.2862e-01, -7.0163e-02, -8.2409e-02,  ..., -4.1030e-02,\n",
            "           -1.1463e-01, -8.5673e-02],\n",
            "          ...,\n",
            "          [-1.3838e-01, -5.6336e-02, -6.0371e-02,  ...,  4.0759e-03,\n",
            "           -7.4124e-03,  3.1254e-02],\n",
            "          [-1.3245e-01, -1.8066e-02, -2.3995e-02,  ...,  6.3334e-02,\n",
            "            8.0102e-02,  1.0305e-01],\n",
            "          [-3.1302e-02,  6.3442e-02,  9.5612e-02,  ...,  2.0618e-01,\n",
            "            1.6517e-01,  7.7537e-02]]]], device='cuda:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>),)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self=ReLU(), input=tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01...da:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>))\u001b[0m\n",
            "\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mF.relu\u001b[0m \u001b[0;34m= <function relu at 0x7f8998ac0d90>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01,  ...,  5.2667e-01,\n",
            "            5.5237e-01,  4.6490e-01],\n",
            "          [ 3.2353e-01,  6.8259e-01,  7.8043e-01,  ...,  6.8623e-01,\n",
            "            6.8309e-01,  6.8942e-01],\n",
            "          [ 3.0407e-01,  7.1957e-01,  8.8579e-01,  ...,  7.1020e-01,\n",
            "            7.0813e-01,  7.1430e-01],\n",
            "          ...,\n",
            "          [ 3.8517e-01,  7.7096e-01,  8.5553e-01,  ...,  8.4784e-01,\n",
            "            8.8967e-01,  8.5234e-01],\n",
            "          [ 3.4952e-01,  7.5828e-01,  9.1787e-01,  ...,  8.3961e-01,\n",
            "            9.5525e-01,  8.5680e-01],\n",
            "          [ 8.4299e-02,  3.4485e-01,  4.2244e-01,  ...,  3.3204e-01,\n",
            "            4.3116e-01,  4.7426e-01]],\n",
            "\n",
            "         [[-1.6261e-01, -7.5415e-02,  8.9645e-03,  ..., -2.0193e-02,\n",
            "            2.7943e-04, -1.7276e-03],\n",
            "          [-6.3013e-02, -1.2413e-02,  7.7958e-02,  ...,  8.0224e-02,\n",
            "            1.2833e-01,  6.6621e-02],\n",
            "          [-4.8644e-02,  9.5492e-02,  2.3655e-01,  ...,  2.2618e-01,\n",
            "            2.7108e-01,  1.6030e-01],\n",
            "          ...,\n",
            "          [-3.8225e-02,  2.3628e-01,  2.8129e-01,  ...,  1.5612e-01,\n",
            "            1.6205e-01,  1.6639e-01],\n",
            "          [ 8.2544e-03,  1.7176e-01,  2.2643e-01,  ...,  1.0285e-01,\n",
            "            2.3193e-01,  2.1735e-01],\n",
            "          [-4.5093e-02,  6.6791e-02,  8.0809e-02,  ...,  1.0619e-01,\n",
            "            4.5429e-02,  6.7398e-02]],\n",
            "\n",
            "         [[-1.7757e-01, -6.6883e-02, -1.2870e-01,  ..., -1.2277e-01,\n",
            "           -8.6087e-02, -4.9190e-02],\n",
            "          [-2.2887e-01, -4.9538e-03, -1.6677e-02,  ..., -7.4911e-02,\n",
            "           -4.7620e-02,  1.2085e-02],\n",
            "          [-1.7611e-01,  6.9240e-02,  3.3180e-02,  ..., -2.5870e-02,\n",
            "            5.3273e-03,  1.8564e-02],\n",
            "          ...,\n",
            "          [-2.3840e-01,  1.1302e-01,  1.0345e-01,  ...,  7.6853e-02,\n",
            "            7.7509e-02,  1.0883e-01],\n",
            "          [-2.8322e-01, -3.9816e-02, -2.9238e-02,  ...,  5.8792e-03,\n",
            "            5.7806e-03,  6.0865e-02],\n",
            "          [-1.8434e-02,  1.4488e-01,  2.8176e-01,  ...,  2.2517e-01,\n",
            "            2.4294e-01,  2.5818e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7776e-02,  2.7535e-01,  2.2139e-01,  ...,  1.4856e-01,\n",
            "            1.3826e-01,  1.6213e-01],\n",
            "          [ 9.0671e-02,  1.2583e-01,  4.7118e-02,  ..., -1.2368e-03,\n",
            "            3.4674e-02,  3.8269e-02],\n",
            "          [ 5.7875e-02, -3.2173e-02, -3.6749e-02,  ..., -4.1819e-02,\n",
            "           -2.2558e-02,  5.5626e-05],\n",
            "          ...,\n",
            "          [ 6.9382e-03,  2.0947e-02, -4.9817e-03,  ...,  2.9012e-03,\n",
            "            2.1494e-02,  1.0317e-01],\n",
            "          [ 5.4558e-02,  9.8283e-02, -7.0156e-04,  ...,  2.7193e-02,\n",
            "            1.1683e-01,  1.2481e-01],\n",
            "          [-6.6755e-02, -1.4735e-01, -2.2934e-01,  ..., -1.9050e-01,\n",
            "           -6.0468e-02, -3.2745e-02]],\n",
            "\n",
            "         [[-8.9371e-02,  1.1433e-02, -1.7514e-02,  ..., -2.4120e-02,\n",
            "            6.1822e-02, -1.3374e-01],\n",
            "          [ 1.7685e-01,  2.3977e-01,  2.5490e-01,  ...,  2.3110e-01,\n",
            "            3.3218e-01, -5.5621e-02],\n",
            "          [ 3.4207e-01,  3.4190e-01,  4.1957e-01,  ...,  3.5915e-01,\n",
            "            4.6486e-01,  3.2820e-02],\n",
            "          ...,\n",
            "          [ 3.3726e-01,  3.7194e-01,  3.2754e-01,  ...,  3.3786e-01,\n",
            "            4.0417e-01,  1.6520e-02],\n",
            "          [ 3.0273e-01,  3.7899e-01,  3.0671e-01,  ...,  3.3068e-01,\n",
            "            4.6788e-01,  1.2872e-02],\n",
            "          [ 3.2531e-01,  2.8950e-01,  2.5689e-01,  ...,  3.1262e-01,\n",
            "            3.0557e-01, -4.5271e-02]],\n",
            "\n",
            "         [[-1.4164e-01, -9.9954e-02, -2.0803e-01,  ..., -1.6111e-01,\n",
            "           -1.8806e-01, -1.6816e-02],\n",
            "          [-1.2879e-01, -7.2904e-02, -1.2950e-01,  ..., -8.4548e-02,\n",
            "           -1.2626e-01, -9.2979e-02],\n",
            "          [-8.1983e-02, -4.6783e-02, -5.9240e-02,  ..., -6.6736e-03,\n",
            "           -9.0917e-02, -7.3542e-02],\n",
            "          ...,\n",
            "          [-1.0109e-01, -1.8327e-02,  1.9710e-02,  ...,  5.8757e-02,\n",
            "           -3.7721e-02,  1.4710e-03],\n",
            "          [-7.0754e-02, -5.0375e-02, -8.8741e-02,  ...,  9.0158e-02,\n",
            "            2.3188e-02, -1.2490e-02],\n",
            "          [ 1.4627e-02,  3.4848e-02,  9.1501e-02,  ...,  1.0077e-01,\n",
            "            8.5178e-02,  9.2107e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1936e-01,  4.8755e-01,  5.3338e-01,  ...,  5.4434e-01,\n",
            "            5.6995e-01,  4.5253e-01],\n",
            "          [ 3.2122e-01,  6.3739e-01,  6.8355e-01,  ...,  6.6625e-01,\n",
            "            7.2255e-01,  6.8929e-01],\n",
            "          [ 3.1748e-01,  6.5308e-01,  7.1021e-01,  ...,  6.8244e-01,\n",
            "            7.1051e-01,  7.4026e-01],\n",
            "          ...,\n",
            "          [ 3.5199e-01,  6.7922e-01,  7.2209e-01,  ...,  7.9005e-01,\n",
            "            8.5600e-01,  8.3584e-01],\n",
            "          [ 3.9327e-01,  7.4837e-01,  7.9135e-01,  ...,  8.3054e-01,\n",
            "            8.6740e-01,  8.2597e-01],\n",
            "          [ 7.4166e-02,  3.0505e-01,  3.4141e-01,  ...,  3.3958e-01,\n",
            "            4.0208e-01,  4.5727e-01]],\n",
            "\n",
            "         [[-1.6369e-01, -9.1060e-02,  5.3837e-03,  ..., -1.7801e-02,\n",
            "            5.3160e-03, -1.0549e-02],\n",
            "          [-1.0814e-01, -7.1165e-03,  1.1115e-01,  ...,  8.2625e-02,\n",
            "            1.1213e-01,  7.4539e-02],\n",
            "          [-2.7054e-02,  1.3876e-01,  2.8103e-01,  ...,  2.4338e-01,\n",
            "            2.5727e-01,  1.6102e-01],\n",
            "          ...,\n",
            "          [-2.9401e-02,  9.8652e-02,  2.2603e-01,  ...,  2.2084e-01,\n",
            "            1.8632e-01,  1.8653e-01],\n",
            "          [-1.9563e-02,  9.1123e-02,  2.0794e-01,  ...,  1.5052e-01,\n",
            "            1.5083e-01,  1.5547e-01],\n",
            "          [-7.0914e-02, -1.5331e-02,  7.0039e-02,  ...,  8.2683e-02,\n",
            "            6.0083e-02,  8.3643e-02]],\n",
            "\n",
            "         [[-1.7497e-01, -5.3898e-02, -1.0758e-01,  ..., -1.2381e-01,\n",
            "           -9.0082e-02, -4.7127e-02],\n",
            "          [-2.2501e-01,  4.1229e-03, -3.9401e-02,  ..., -6.1151e-02,\n",
            "           -3.2936e-02, -2.1774e-02],\n",
            "          [-2.7936e-01,  1.7223e-02, -2.2377e-02,  ..., -1.9218e-02,\n",
            "            3.0732e-02,  1.6587e-02],\n",
            "          ...,\n",
            "          [-2.6118e-01,  2.4114e-02,  4.9451e-03,  ...,  4.1661e-02,\n",
            "            6.0266e-02,  1.0456e-01],\n",
            "          [-3.1828e-01, -4.3081e-02, -5.6697e-02,  ...,  1.5097e-02,\n",
            "            1.2163e-02,  9.7990e-02],\n",
            "          [ 1.2590e-02,  2.9730e-01,  3.2151e-01,  ...,  3.2187e-01,\n",
            "            2.2438e-01,  1.5837e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9638e-02,  2.3557e-01,  1.8097e-01,  ...,  1.4664e-01,\n",
            "            1.4341e-01,  1.1406e-01],\n",
            "          [ 3.9965e-02,  5.4214e-02,  1.1951e-02,  ..., -1.1070e-03,\n",
            "            3.1058e-02,  1.8292e-02],\n",
            "          [-5.5255e-03, -1.5887e-02, -4.7001e-02,  ..., -5.9117e-02,\n",
            "           -1.9441e-02,  2.0055e-04],\n",
            "          ...,\n",
            "          [ 2.1075e-04, -1.3586e-02, -5.8728e-02,  ..., -2.1825e-02,\n",
            "            1.6546e-03,  6.4870e-02],\n",
            "          [ 6.1808e-02,  6.3894e-02,  8.7541e-05,  ...,  2.9056e-02,\n",
            "            6.2418e-02,  1.1499e-01],\n",
            "          [-2.9677e-03, -1.5113e-01, -1.9361e-01,  ..., -1.7929e-01,\n",
            "           -9.4297e-02, -1.2342e-02]],\n",
            "\n",
            "         [[-9.8626e-02,  8.9007e-03, -7.0347e-03,  ..., -1.7574e-04,\n",
            "            2.3958e-02, -1.3545e-01],\n",
            "          [ 1.6619e-01,  2.5718e-01,  2.6824e-01,  ...,  2.2335e-01,\n",
            "            2.8343e-01, -9.0829e-02],\n",
            "          [ 2.7654e-01,  3.6372e-01,  3.9330e-01,  ...,  3.5126e-01,\n",
            "            4.3444e-01,  5.7304e-03],\n",
            "          ...,\n",
            "          [ 2.4019e-01,  3.0182e-01,  3.3140e-01,  ...,  3.6036e-01,\n",
            "            4.4168e-01,  2.0328e-02],\n",
            "          [ 2.3956e-01,  3.3566e-01,  3.5492e-01,  ...,  3.5695e-01,\n",
            "            4.2771e-01,  2.8168e-02],\n",
            "          [ 3.5225e-01,  3.3300e-01,  3.0612e-01,  ...,  2.4498e-01,\n",
            "            3.3060e-01,  4.2823e-03]],\n",
            "\n",
            "         [[-1.4233e-01, -1.1079e-01, -1.8388e-01,  ..., -1.6999e-01,\n",
            "           -1.6591e-01, -2.9386e-02],\n",
            "          [-1.4843e-01, -8.5695e-02, -1.2984e-01,  ..., -1.1390e-01,\n",
            "           -1.5642e-01, -8.3582e-02],\n",
            "          [-1.2862e-01, -7.0163e-02, -8.2409e-02,  ..., -4.1030e-02,\n",
            "           -1.1463e-01, -8.5673e-02],\n",
            "          ...,\n",
            "          [-1.3838e-01, -5.6336e-02, -6.0371e-02,  ...,  4.0759e-03,\n",
            "           -7.4124e-03,  3.1254e-02],\n",
            "          [-1.3245e-01, -1.8066e-02, -2.3995e-02,  ...,  6.3334e-02,\n",
            "            8.0102e-02,  1.0305e-01],\n",
            "          [-3.1302e-02,  6.3442e-02,  9.5612e-02,  ...,  2.0618e-01,\n",
            "            1.6517e-01,  7.7537e-02]]]], device='cuda:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36minplace\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.inplace\u001b[0m \u001b[0;34m= False\u001b[0m\n",
            "\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input=tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01...da:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>), inplace=False)\u001b[0m\n",
            "\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mtorch.relu\u001b[0m \u001b[0;34m= <built-in method relu of type object at 0x7f89e1da9220>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[[[ 4.3355e-01,  5.2693e-01,  5.7062e-01,  ...,  5.2667e-01,\n",
            "            5.5237e-01,  4.6490e-01],\n",
            "          [ 3.2353e-01,  6.8259e-01,  7.8043e-01,  ...,  6.8623e-01,\n",
            "            6.8309e-01,  6.8942e-01],\n",
            "          [ 3.0407e-01,  7.1957e-01,  8.8579e-01,  ...,  7.1020e-01,\n",
            "            7.0813e-01,  7.1430e-01],\n",
            "          ...,\n",
            "          [ 3.8517e-01,  7.7096e-01,  8.5553e-01,  ...,  8.4784e-01,\n",
            "            8.8967e-01,  8.5234e-01],\n",
            "          [ 3.4952e-01,  7.5828e-01,  9.1787e-01,  ...,  8.3961e-01,\n",
            "            9.5525e-01,  8.5680e-01],\n",
            "          [ 8.4299e-02,  3.4485e-01,  4.2244e-01,  ...,  3.3204e-01,\n",
            "            4.3116e-01,  4.7426e-01]],\n",
            "\n",
            "         [[-1.6261e-01, -7.5415e-02,  8.9645e-03,  ..., -2.0193e-02,\n",
            "            2.7943e-04, -1.7276e-03],\n",
            "          [-6.3013e-02, -1.2413e-02,  7.7958e-02,  ...,  8.0224e-02,\n",
            "            1.2833e-01,  6.6621e-02],\n",
            "          [-4.8644e-02,  9.5492e-02,  2.3655e-01,  ...,  2.2618e-01,\n",
            "            2.7108e-01,  1.6030e-01],\n",
            "          ...,\n",
            "          [-3.8225e-02,  2.3628e-01,  2.8129e-01,  ...,  1.5612e-01,\n",
            "            1.6205e-01,  1.6639e-01],\n",
            "          [ 8.2544e-03,  1.7176e-01,  2.2643e-01,  ...,  1.0285e-01,\n",
            "            2.3193e-01,  2.1735e-01],\n",
            "          [-4.5093e-02,  6.6791e-02,  8.0809e-02,  ...,  1.0619e-01,\n",
            "            4.5429e-02,  6.7398e-02]],\n",
            "\n",
            "         [[-1.7757e-01, -6.6883e-02, -1.2870e-01,  ..., -1.2277e-01,\n",
            "           -8.6087e-02, -4.9190e-02],\n",
            "          [-2.2887e-01, -4.9538e-03, -1.6677e-02,  ..., -7.4911e-02,\n",
            "           -4.7620e-02,  1.2085e-02],\n",
            "          [-1.7611e-01,  6.9240e-02,  3.3180e-02,  ..., -2.5870e-02,\n",
            "            5.3273e-03,  1.8564e-02],\n",
            "          ...,\n",
            "          [-2.3840e-01,  1.1302e-01,  1.0345e-01,  ...,  7.6853e-02,\n",
            "            7.7509e-02,  1.0883e-01],\n",
            "          [-2.8322e-01, -3.9816e-02, -2.9238e-02,  ...,  5.8792e-03,\n",
            "            5.7806e-03,  6.0865e-02],\n",
            "          [-1.8434e-02,  1.4488e-01,  2.8176e-01,  ...,  2.2517e-01,\n",
            "            2.4294e-01,  2.5818e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7776e-02,  2.7535e-01,  2.2139e-01,  ...,  1.4856e-01,\n",
            "            1.3826e-01,  1.6213e-01],\n",
            "          [ 9.0671e-02,  1.2583e-01,  4.7118e-02,  ..., -1.2368e-03,\n",
            "            3.4674e-02,  3.8269e-02],\n",
            "          [ 5.7875e-02, -3.2173e-02, -3.6749e-02,  ..., -4.1819e-02,\n",
            "           -2.2558e-02,  5.5626e-05],\n",
            "          ...,\n",
            "          [ 6.9382e-03,  2.0947e-02, -4.9817e-03,  ...,  2.9012e-03,\n",
            "            2.1494e-02,  1.0317e-01],\n",
            "          [ 5.4558e-02,  9.8283e-02, -7.0156e-04,  ...,  2.7193e-02,\n",
            "            1.1683e-01,  1.2481e-01],\n",
            "          [-6.6755e-02, -1.4735e-01, -2.2934e-01,  ..., -1.9050e-01,\n",
            "           -6.0468e-02, -3.2745e-02]],\n",
            "\n",
            "         [[-8.9371e-02,  1.1433e-02, -1.7514e-02,  ..., -2.4120e-02,\n",
            "            6.1822e-02, -1.3374e-01],\n",
            "          [ 1.7685e-01,  2.3977e-01,  2.5490e-01,  ...,  2.3110e-01,\n",
            "            3.3218e-01, -5.5621e-02],\n",
            "          [ 3.4207e-01,  3.4190e-01,  4.1957e-01,  ...,  3.5915e-01,\n",
            "            4.6486e-01,  3.2820e-02],\n",
            "          ...,\n",
            "          [ 3.3726e-01,  3.7194e-01,  3.2754e-01,  ...,  3.3786e-01,\n",
            "            4.0417e-01,  1.6520e-02],\n",
            "          [ 3.0273e-01,  3.7899e-01,  3.0671e-01,  ...,  3.3068e-01,\n",
            "            4.6788e-01,  1.2872e-02],\n",
            "          [ 3.2531e-01,  2.8950e-01,  2.5689e-01,  ...,  3.1262e-01,\n",
            "            3.0557e-01, -4.5271e-02]],\n",
            "\n",
            "         [[-1.4164e-01, -9.9954e-02, -2.0803e-01,  ..., -1.6111e-01,\n",
            "           -1.8806e-01, -1.6816e-02],\n",
            "          [-1.2879e-01, -7.2904e-02, -1.2950e-01,  ..., -8.4548e-02,\n",
            "           -1.2626e-01, -9.2979e-02],\n",
            "          [-8.1983e-02, -4.6783e-02, -5.9240e-02,  ..., -6.6736e-03,\n",
            "           -9.0917e-02, -7.3542e-02],\n",
            "          ...,\n",
            "          [-1.0109e-01, -1.8327e-02,  1.9710e-02,  ...,  5.8757e-02,\n",
            "           -3.7721e-02,  1.4710e-03],\n",
            "          [-7.0754e-02, -5.0375e-02, -8.8741e-02,  ...,  9.0158e-02,\n",
            "            2.3188e-02, -1.2490e-02],\n",
            "          [ 1.4627e-02,  3.4848e-02,  9.1501e-02,  ...,  1.0077e-01,\n",
            "            8.5178e-02,  9.2107e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1936e-01,  4.8755e-01,  5.3338e-01,  ...,  5.4434e-01,\n",
            "            5.6995e-01,  4.5253e-01],\n",
            "          [ 3.2122e-01,  6.3739e-01,  6.8355e-01,  ...,  6.6625e-01,\n",
            "            7.2255e-01,  6.8929e-01],\n",
            "          [ 3.1748e-01,  6.5308e-01,  7.1021e-01,  ...,  6.8244e-01,\n",
            "            7.1051e-01,  7.4026e-01],\n",
            "          ...,\n",
            "          [ 3.5199e-01,  6.7922e-01,  7.2209e-01,  ...,  7.9005e-01,\n",
            "            8.5600e-01,  8.3584e-01],\n",
            "          [ 3.9327e-01,  7.4837e-01,  7.9135e-01,  ...,  8.3054e-01,\n",
            "            8.6740e-01,  8.2597e-01],\n",
            "          [ 7.4166e-02,  3.0505e-01,  3.4141e-01,  ...,  3.3958e-01,\n",
            "            4.0208e-01,  4.5727e-01]],\n",
            "\n",
            "         [[-1.6369e-01, -9.1060e-02,  5.3837e-03,  ..., -1.7801e-02,\n",
            "            5.3160e-03, -1.0549e-02],\n",
            "          [-1.0814e-01, -7.1165e-03,  1.1115e-01,  ...,  8.2625e-02,\n",
            "            1.1213e-01,  7.4539e-02],\n",
            "          [-2.7054e-02,  1.3876e-01,  2.8103e-01,  ...,  2.4338e-01,\n",
            "            2.5727e-01,  1.6102e-01],\n",
            "          ...,\n",
            "          [-2.9401e-02,  9.8652e-02,  2.2603e-01,  ...,  2.2084e-01,\n",
            "            1.8632e-01,  1.8653e-01],\n",
            "          [-1.9563e-02,  9.1123e-02,  2.0794e-01,  ...,  1.5052e-01,\n",
            "            1.5083e-01,  1.5547e-01],\n",
            "          [-7.0914e-02, -1.5331e-02,  7.0039e-02,  ...,  8.2683e-02,\n",
            "            6.0083e-02,  8.3643e-02]],\n",
            "\n",
            "         [[-1.7497e-01, -5.3898e-02, -1.0758e-01,  ..., -1.2381e-01,\n",
            "           -9.0082e-02, -4.7127e-02],\n",
            "          [-2.2501e-01,  4.1229e-03, -3.9401e-02,  ..., -6.1151e-02,\n",
            "           -3.2936e-02, -2.1774e-02],\n",
            "          [-2.7936e-01,  1.7223e-02, -2.2377e-02,  ..., -1.9218e-02,\n",
            "            3.0732e-02,  1.6587e-02],\n",
            "          ...,\n",
            "          [-2.6118e-01,  2.4114e-02,  4.9451e-03,  ...,  4.1661e-02,\n",
            "            6.0266e-02,  1.0456e-01],\n",
            "          [-3.1828e-01, -4.3081e-02, -5.6697e-02,  ...,  1.5097e-02,\n",
            "            1.2163e-02,  9.7990e-02],\n",
            "          [ 1.2590e-02,  2.9730e-01,  3.2151e-01,  ...,  3.2187e-01,\n",
            "            2.2438e-01,  1.5837e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9638e-02,  2.3557e-01,  1.8097e-01,  ...,  1.4664e-01,\n",
            "            1.4341e-01,  1.1406e-01],\n",
            "          [ 3.9965e-02,  5.4214e-02,  1.1951e-02,  ..., -1.1070e-03,\n",
            "            3.1058e-02,  1.8292e-02],\n",
            "          [-5.5255e-03, -1.5887e-02, -4.7001e-02,  ..., -5.9117e-02,\n",
            "           -1.9441e-02,  2.0055e-04],\n",
            "          ...,\n",
            "          [ 2.1075e-04, -1.3586e-02, -5.8728e-02,  ..., -2.1825e-02,\n",
            "            1.6546e-03,  6.4870e-02],\n",
            "          [ 6.1808e-02,  6.3894e-02,  8.7541e-05,  ...,  2.9056e-02,\n",
            "            6.2418e-02,  1.1499e-01],\n",
            "          [-2.9677e-03, -1.5113e-01, -1.9361e-01,  ..., -1.7929e-01,\n",
            "           -9.4297e-02, -1.2342e-02]],\n",
            "\n",
            "         [[-9.8626e-02,  8.9007e-03, -7.0347e-03,  ..., -1.7574e-04,\n",
            "            2.3958e-02, -1.3545e-01],\n",
            "          [ 1.6619e-01,  2.5718e-01,  2.6824e-01,  ...,  2.2335e-01,\n",
            "            2.8343e-01, -9.0829e-02],\n",
            "          [ 2.7654e-01,  3.6372e-01,  3.9330e-01,  ...,  3.5126e-01,\n",
            "            4.3444e-01,  5.7304e-03],\n",
            "          ...,\n",
            "          [ 2.4019e-01,  3.0182e-01,  3.3140e-01,  ...,  3.6036e-01,\n",
            "            4.4168e-01,  2.0328e-02],\n",
            "          [ 2.3956e-01,  3.3566e-01,  3.5492e-01,  ...,  3.5695e-01,\n",
            "            4.2771e-01,  2.8168e-02],\n",
            "          [ 3.5225e-01,  3.3300e-01,  3.0612e-01,  ...,  2.4498e-01,\n",
            "            3.3060e-01,  4.2823e-03]],\n",
            "\n",
            "         [[-1.4233e-01, -1.1079e-01, -1.8388e-01,  ..., -1.6999e-01,\n",
            "           -1.6591e-01, -2.9386e-02],\n",
            "          [-1.4843e-01, -8.5695e-02, -1.2984e-01,  ..., -1.1390e-01,\n",
            "           -1.5642e-01, -8.3582e-02],\n",
            "          [-1.2862e-01, -7.0163e-02, -8.2409e-02,  ..., -4.1030e-02,\n",
            "           -1.1463e-01, -8.5673e-02],\n",
            "          ...,\n",
            "          [-1.3838e-01, -5.6336e-02, -6.0371e-02,  ...,  4.0759e-03,\n",
            "           -7.4124e-03,  3.1254e-02],\n",
            "          [-1.3245e-01, -1.8066e-02, -2.3995e-02,  ...,  6.3334e-02,\n",
            "            8.0102e-02,  1.0305e-01],\n",
            "          [-3.1302e-02,  6.3442e-02,  9.5612e-02,  ...,  2.0618e-01,\n",
            "            1.6517e-01,  7.7537e-02]]]], device='cuda:0',\n",
            "       grad_fn=<CudnnConvolutionBackward>)\u001b[0m\n",
            "\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 15.16 GiB already allocated; 13.88 MiB free; 31.02 MiB cached)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYdYGziroaq",
        "colab_type": "text"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdkwEMkFrv_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Loss\n",
        "a, b = zip(*val_losses)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dshGPo7xXKLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Accuracy\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Accuracy')\n",
        "a, b = zip(*val_acc)\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ltr9lNr2ag",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGLEzUYIr77s",
        "colab_type": "text"
      },
      "source": [
        "The above CNN architecture achieves...\n",
        "\n",
        "These are the contributions and performance of the model..."
      ]
    }
  ]
}