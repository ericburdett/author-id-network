{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/author-id-network/blob/master/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOdWuCQNoNv",
        "colab_type": "text"
      },
      "source": [
        "# **Author Identification**\n",
        "#### Eric Burdett\n",
        "\n",
        "This notebook contains code that can successfully identify authors given a page of handwritten text. The datasets used come from the Missionary Journals dataset that is made available from the BYU library. This work is based off of the following papers:\n",
        "\n",
        "*   Paper #1\n",
        "*   Paper #2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmQvEN8qCD2",
        "colab_type": "text"
      },
      "source": [
        "##Install PyTorch and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgvRdcMpTUY",
        "colab_type": "code",
        "outputId": "caf1b837-ee89-4132-ba37-27a08ffdfb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgyBKjilpXsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a89edd8d-f72e-4141-d939-30e8d06aa576"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HigOWkfRqRuJ",
        "colab_type": "text"
      },
      "source": [
        "##Import & Create Missionary Journal Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIMmLHE0P7zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the dataset over to colab\n",
        "!cp \"drive/My Drive/datasets/missionary.tar.gz\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3MhFQ3PmZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract into /content/missionary\n",
        "!tar xvzf missionary.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIGyUuMAqbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MissionaryDataset(Dataset):\n",
        "  def __init__(self, size=256):\n",
        "    if not os.path.exists('/content/missionary'):\n",
        "      raise Exception('Missionary dataset does not exist in /content/missionary')\n",
        "\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder('/content/missionary',\n",
        "        transform=transforms.Compose([transforms.Resize(size), transforms.ToTensor()]))\n",
        "\n",
        "  def num_classes(self):\n",
        "    return len(self.dataset_folder.class_to_idx)\n",
        "\n",
        "  def idx_to_class(self, idx):\n",
        "    for key, value in self.dataset_folder.class_to_idx.items():\n",
        "      if value == idx:\n",
        "        return key\n",
        "    \n",
        "    raise Exception('Class not found for index ' + idx)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.dataset_folder[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ExaArQzRi-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MissionaryDataset()\n",
        "img, label = dataset.__getitem__(1)\n",
        "print(dataset.idx_to_class(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoyVcM3Uqsjn",
        "colab_type": "text"
      },
      "source": [
        "##Create our model using a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJAHFVsbrBcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AuthorIdNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(DeepWriterNetwork, self).__init__()\n",
        "\n",
        "    x, y = dataset[0]\n",
        "    in_channels, height, width = x.size()\n",
        "\n",
        "    num_classes = dataset.num_classes()\n",
        "\n",
        "    CONV1_CHANNELS = 96\n",
        "    CONV1_SIZE = (5, 5)\n",
        "    CONV1_STRIDE = 2 \n",
        "    CONV1_PADDING = 0\n",
        "    CONV2_5_CHANNELS = 256\n",
        "    CONV2_5_SIZE = (3, 3)\n",
        "    CONV2_5_STRIDE = 1\n",
        "    CONV2_5_PADDING = 1\n",
        "    CONV3_4_CHANNELS = 384\n",
        "    CONV3_4_SIZE = (3, 3)\n",
        "    CONV3_4_STRIDE = 1\n",
        "    CONV3_4_PADDING = 1\n",
        "    FC_COUNT = 1024\n",
        "\n",
        "    MP_SIZE= (3, 3)\n",
        "    MP_STRIDE = 2\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels, CONV1_CHANNELS, CONV1_SIZE, stride=CONV1_STRIDE, padding=CONV1_PADDING)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.mp1 = nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE)\n",
        "    self.conv2 = nn.Conv2d(CONV1_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.mp2 =  nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE)\n",
        "    self.conv3 = nn.Conv2d(CONV2_5_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.conv4 = nn.Conv2d(CONV3_4_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING)\n",
        "    self.relu4 = nn.ReLU()\n",
        "    self.conv5 = nn.Conv2d(CONV3_4_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING)\n",
        "    self.relu5 = nn.ReLU()\n",
        "    self.mp3 = nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE)\n",
        "    self.fc1 = nn.Linear(FC_COUNT, FC_COUNT, bias=True)\n",
        "    self.relu6 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(FC_COUNT, FC_COUNT, bias=True)\n",
        "    self.relu7 = nn.ReLU()\n",
        "    self.drop = nn.Dropout(p=0.5)\n",
        "    self.soft = nn.Softmax(dim=3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    conv1_out = self.conv1(x)\n",
        "    relu1_out = self.relu1(conv1_out)\n",
        "    mp1_out = self.mp1(relu1_out)\n",
        "    conv2_out = self.conv1(mp1_out)\n",
        "    relu2_out = self.relu2(conv2_out)\n",
        "    mp2_out = self.mp2(relu2_out)\n",
        "    conv3_out = self.conv1(relu2_out)\n",
        "    relu3_out = self.relu3(conv3_out)\n",
        "    conv4_out = self.conv1(relu3_out)\n",
        "    relu4_out = self.relu4(conv4_out)\n",
        "    conv5_out = self.conv1(relu4_out)\n",
        "    relu5_out = self.relu5(conv5_out)\n",
        "    mp3_out = self.mp3(relu5_out)\n",
        "    fc1_out = self.fc1(mp3_out)\n",
        "    relu6_out = self.relu6(fc1_out)\n",
        "    fc7_out = self.fc2(relu6_out)\n",
        "    drop_out = self.drop(fc7_out)\n",
        "    soft_out = self.soft(drop_out)\n",
        "\n",
        "    return soft_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl7tVR2ErV7M",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_NcVwOrdVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 1\n",
        "\n",
        "def train():\n",
        "  dataset = MissionaryDataset()\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(dataset, [.8, .2])\n",
        "\n",
        "  model = AuthorIdNetwork(dataset)\n",
        "  model = model.cuda()\n",
        "\n",
        "  objective = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(moel.parameters(), lr=1e-3)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=8,\n",
        "                            num_workers=4,\n",
        "                            pin_memory=True,\n",
        "                            shuffle=True)\n",
        "  \n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=8,\n",
        "                          num_workers=4,\n",
        "                          pin_memory=True,\n",
        "                          shuffle=True)\n",
        "  \n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  train_accs = []\n",
        "  val_accs = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "\n",
        "    for batch (x, y_truth) in enumerate(train_loader):\n",
        "      gc.collect()\n",
        "      x, y_truth = x.cuda(async=True), y_truth.cuda(async=True).long()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_hat = model(x)\n",
        "\n",
        "      accuracy = torch.eq(y_hat.argmax(1), y_truth).float().mean()\n",
        "      loss = objective(y_hat, y_truth)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "      train_accs.append(accuracy.item())\n",
        "\n",
        "      loop.set_description('epoch:{}, loss:{:.4f}, accuracy:{:.4f}'.format(epoch, loss.item(), accuracy.item()))\n",
        "      loop.update(1)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 10 == 0:\n",
        "        gc.collect()\n",
        "\n",
        "        val_single_acc = []\n",
        "        val_single_loss = []\n",
        "\n",
        "        for val_x, val_y_truth in val_loader:\n",
        "          gc.collect()\n",
        "          val_x, val_y_truth = val_x.cuda(async=True), val_y_truth.cuda(async=True).long()\n",
        "\n",
        "          val_y_hat = model(val_x)\n",
        "\n",
        "          val_accuracy = torch.eq(val_y_hat.argmax(1), val_y_truth)\n",
        "          val_loss = objective(val_y_hat, val_y_truth)\n",
        "\n",
        "          val_single_acc.append(val_accuracy)\n",
        "          val_single_loss.append(val_loss)\n",
        "\n",
        "        val_accs.append(val_single_acc)\n",
        "        val_losses.append(val_single_loss)\n",
        "    \n",
        "    loop.close()\n",
        "\n",
        "  return model, train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "try:\n",
        "  model, train_losses, val_losses, train_accs, val_accs = train()\n",
        "  gc.collect()\n",
        "except:\n",
        "  gc.collect()\n",
        "  __ITB__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYdYGziroaq",
        "colab_type": "text"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdkwEMkFrv_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Loss\n",
        "a, b = zip(*val_losses)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dshGPo7xXKLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Accuracy\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Accuracy')\n",
        "a, b = zip(*val_acc)\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ltr9lNr2ag",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGLEzUYIr77s",
        "colab_type": "text"
      },
      "source": [
        "The above CNN architecture achieves...\n",
        "\n",
        "These are the contributions and performance of the model..."
      ]
    }
  ]
}