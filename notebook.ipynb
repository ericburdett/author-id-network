{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/author-id-network/blob/master/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOdWuCQNoNv",
        "colab_type": "text"
      },
      "source": [
        "# **Author Identification**\n",
        "#### Eric Burdett\n",
        "\n",
        "This notebook contains code that can successfully identify authors given a page of handwritten text. The datasets used come from the Missionary Journals dataset that is made available from the BYU library. This work is based off of the following papers:\n",
        "\n",
        "*   Paper #1\n",
        "*   Paper #2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmQvEN8qCD2",
        "colab_type": "text"
      },
      "source": [
        "##Install PyTorch and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtgvRdcMpTUY",
        "colab_type": "code",
        "outputId": "caf1b837-ee89-4132-ba37-27a08ffdfb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgyBKjilpXsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf4ac695-9cc4-4396-8acc-bb02b83692bf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "import pdb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HigOWkfRqRuJ",
        "colab_type": "text"
      },
      "source": [
        "##Import & Create Missionary Journal Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIMmLHE0P7zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the dataset over to colab\n",
        "!cp \"drive/My Drive/datasets/missionary.tar.gz\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3MhFQ3PmZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract into /content/missionary\n",
        "!tar xvzf missionary.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIGyUuMAqbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MissionaryDataset(Dataset):\n",
        "  def __init__(self, size=256):\n",
        "    if not os.path.exists('/content/missionary'):\n",
        "      raise Exception('Missionary dataset does not exist in /content/missionary')\n",
        "\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder('/content/missionary',\n",
        "        transform=transforms.Compose([transforms.Resize(size), transforms.ToTensor()]))\n",
        "\n",
        "  def num_classes(self):\n",
        "    return len(self.dataset_folder.class_to_idx)\n",
        "\n",
        "  def idx_to_class(self, idx):\n",
        "    for key, value in self.dataset_folder.class_to_idx.items():\n",
        "      if value == idx:\n",
        "        return key\n",
        "    \n",
        "    raise Exception('Class not found for index ' + idx)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.dataset_folder[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ExaArQzRi-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MissionaryDataset()\n",
        "img, label = dataset.__getitem__(1)\n",
        "print(dataset.idx_to_class(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoyVcM3Uqsjn",
        "colab_type": "text"
      },
      "source": [
        "##Create our model using a CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmjWMcJIjVif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJAHFVsbrBcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AuthorIdNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(AuthorIdNetwork, self).__init__()\n",
        "\n",
        "    x, y = dataset[0]\n",
        "    in_channels, height, width = x.size()\n",
        "\n",
        "    num_classes = dataset.num_classes()\n",
        "\n",
        "    CONV1_CHANNELS = 96\n",
        "    CONV1_SIZE = (5, 5)\n",
        "    CONV1_STRIDE = 1\n",
        "    CONV1_PADDING = 2\n",
        "    CONV2_5_CHANNELS = 256 \n",
        "    CONV2_5_SIZE = (3, 3)\n",
        "    CONV2_5_STRIDE = 1\n",
        "    CONV2_5_PADDING = 1\n",
        "    CONV3_4_CHANNELS = 384\n",
        "    CONV3_4_SIZE = (3, 3)\n",
        "    CONV3_4_STRIDE = 1\n",
        "    CONV3_4_PADDING = 1\n",
        "    FC_COUNT = 1024\n",
        "    self.fc_input = BATCH_SIZE * CONV2_5_CHANNELS * (height // 8) * (width // 8)\n",
        "\n",
        "    MP_SIZE= (3, 3)\n",
        "    MP_STRIDE = 2\n",
        "    MP_PADDING = 1\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels, CONV1_CHANNELS, CONV1_SIZE, stride=CONV1_STRIDE, padding=CONV1_PADDING)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.mp1 = nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE, padding=MP_PADDING)\n",
        "    self.conv2 = nn.Conv2d(CONV1_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.mp2 =  nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE, padding=MP_PADDING)\n",
        "    self.conv3 = nn.Conv2d(CONV2_5_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.conv4 = nn.Conv2d(CONV3_4_CHANNELS, CONV3_4_CHANNELS, CONV3_4_SIZE, stride=CONV3_4_STRIDE, padding=CONV3_4_PADDING)\n",
        "    self.relu4 = nn.ReLU()\n",
        "    self.conv5 = nn.Conv2d(CONV3_4_CHANNELS, CONV2_5_CHANNELS, CONV2_5_SIZE, stride=CONV2_5_STRIDE, padding=CONV2_5_PADDING)\n",
        "    self.relu5 = nn.ReLU()\n",
        "    self.mp3 = nn.MaxPool2d(MP_SIZE, stride=MP_STRIDE, padding=MP_PADDING)\n",
        "    self.fc1 = nn.Linear(self.fc_input, FC_COUNT, bias=True)\n",
        "    self.relu6 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(FC_COUNT, num_classes, bias=True)\n",
        "    self.relu7 = nn.ReLU()\n",
        "    self.drop = nn.Dropout(p=0.5)\n",
        "    self.soft = nn.Softmax(dim=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    conv1_out = self.conv1(x)\n",
        "    print('conv1_out:', conv1_out.shape)\n",
        "    relu1_out = self.relu1(conv1_out)\n",
        "    mp1_out = self.mp1(relu1_out)\n",
        "    print('mp1_out:', mp1_out.shape)\n",
        "    conv2_out = self.conv2(mp1_out)\n",
        "    print('conv2_out:', conv2_out.shape)\n",
        "    relu2_out = self.relu2(conv2_out)\n",
        "    mp2_out = self.mp2(relu2_out)\n",
        "    print('mp2_out:', mp2_out.shape)\n",
        "    conv3_out = self.conv3(mp2_out)\n",
        "    print('conv3_out:', conv3_out.shape)\n",
        "    relu3_out = self.relu3(conv3_out)\n",
        "    conv4_out = self.conv4(relu3_out)\n",
        "    print('conv4_out:', conv4_out.shape)\n",
        "    relu4_out = self.relu4(conv4_out)\n",
        "    conv5_out = self.conv5(relu4_out)\n",
        "    print('conv5_out:', conv5_out.shape)\n",
        "    relu5_out = self.relu5(conv5_out)\n",
        "    mp3_out = self.mp3(relu5_out)\n",
        "    print('mp3_out:', mp3_out.shape)\n",
        "    mp3_out_viewed = mp3_out.view(self.fc_input)\n",
        "    fc1_out = self.fc1(mp3_out_viewed)\n",
        "    print('fc1_out:', fc1_out.shape)\n",
        "    relu6_out = self.relu6(fc1_out)\n",
        "    fc2_out = self.fc2(relu6_out)\n",
        "    print('fc2_out:', fc2_out.shape)\n",
        "    relu7_out = self.relu7(fc2_out)\n",
        "    drop_out = self.drop(relu7_out)\n",
        "    print('drop_out:', drop_out.shape)\n",
        "    soft_out = self.soft(drop_out)\n",
        "    print('soft_out:', soft_out.shape)\n",
        "\n",
        "    return soft_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl7tVR2ErV7M",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU_NcVwOrdVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2e0fb75-6633-4128-fb47-4c7d0d74a693"
      },
      "source": [
        "def train():\n",
        "  dataset = MissionaryDataset()\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(.8 * len(dataset)), int(.2 * len(dataset))])\n",
        "\n",
        "  model = AuthorIdNetwork(dataset)\n",
        "  model = model.cuda()\n",
        "\n",
        "  objective = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=2,\n",
        "                            num_workers=2,\n",
        "                            pin_memory=True,\n",
        "                            shuffle=True)\n",
        "  \n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=2,\n",
        "                          num_workers=2,\n",
        "                          pin_memory=True,\n",
        "                          shuffle=True)\n",
        "  \n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  train_accs = []\n",
        "  val_accs = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "\n",
        "    for batch, (x, y_truth) in enumerate(train_loader):\n",
        "      gc.collect()\n",
        "      x, y_truth = x.cuda(async=True), y_truth.cuda(async=True).long()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_hat = model(x)\n",
        "\n",
        "      pdb.set_trace()\n",
        "\n",
        "      accuracy = torch.eq(y_hat.argmax(), y_truth).float().mean()\n",
        "      loss = objective(y_hat, y_truth)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      train_losses.append(loss.item())\n",
        "      train_accs.append(accuracy.item())\n",
        "\n",
        "      loop.set_description('epoch:{}, loss:{:.4f}, accuracy:{:.4f}'.format(epoch, loss.item(), accuracy.item()))\n",
        "      loop.update(1)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 10 == 0:\n",
        "        gc.collect()\n",
        "\n",
        "        val_single_acc = []\n",
        "        val_single_loss = []\n",
        "\n",
        "        for val_x, val_y_truth in val_loader:\n",
        "          gc.collect()\n",
        "          val_x, val_y_truth = val_x.cuda(async=True), val_y_truth.cuda(async=True).long()\n",
        "\n",
        "          val_y_hat = model(val_x)\n",
        "\n",
        "          val_accuracy = torch.eq(val_y_hat.argmax(), val_y_truth)\n",
        "          val_loss = objective(val_y_hat, val_y_truth)\n",
        "\n",
        "          val_single_acc.append(val_accuracy)\n",
        "          val_single_loss.append(val_loss)\n",
        "\n",
        "        val_accs.append(val_single_acc)\n",
        "        val_losses.append(val_single_loss)\n",
        "    \n",
        "    loop.close()\n",
        "\n",
        "  return model, train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "try:\n",
        "  model, train_losses, val_losses, train_accs, val_accs = train()\n",
        "  gc.collect()\n",
        "except:\n",
        "  gc.collect()\n",
        "  __ITB__()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-96-09357bed6781>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAuthorIdNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mmodel\u001b[0m \u001b[0;34m= AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (mp1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (mp2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu4): ReLU()\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu5): ReLU()\n",
            "  (mp3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2097152, out_features=1024, bias=True)\n",
            "  (relu6): ReLU()\n",
            "  (fc2): Linear(in_features=1024, out_features=55, bias=True)\n",
            "  (relu7): ReLU()\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            ")\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mmodel.cuda\u001b[0m \u001b[0;34m= <bound method Module.cuda of AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (mp1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (mp2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu4): ReLU()\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu5): ReLU()\n",
            "  (mp3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2097152, out_features=1024, bias=True)\n",
            "  (relu6): ReLU()\n",
            "  (fc2): Linear(in_features=1024, out_features=55, bias=True)\n",
            "  (relu7): ReLU()\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            ")>\u001b[0m\n",
            "\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8\u001b[0m   \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self=AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel...(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            "), device=None)\u001b[0m\n",
            "\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    304\u001b[0m         \"\"\"\n",
            "\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself._apply\u001b[0m \u001b[0;34m= <bound method Module._apply of AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu1): ReLU()\n",
            "  (mp1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (mp2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu4): ReLU()\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu5): ReLU()\n",
            "  (mp3): MaxPool2d(kernel_size=(3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2097152, out_features=1024, bias=True)\n",
            "  (relu6): ReLU()\n",
            "  (fc2): Linear(in_features=1024, out_features=55, bias=True)\n",
            "  (relu7): ReLU()\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            ")>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mt\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mt.cuda\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mdevice\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self=AuthorIdNetwork(\n",
            "  (conv1): Conv2d(3, 96, kernel...(p=0.5, inplace=False)\n",
            "  (soft): Softmax(dim=0)\n",
            "), fn=<function Module.cuda.<locals>.<lambda>>)\u001b[0m\n",
            "\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mmodule._apply\u001b[0m \u001b[0;34m= <bound method Module._apply of Linear(in_features=2097152, out_features=1024, bias=True)>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mfn\u001b[0m \u001b[0;34m= <function Module.cuda.<locals>.<lambda> at 0x7f0c61ab4378>\u001b[0m\n",
            "\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    204\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self=Linear(in_features=2097152, out_features=1024, bias=True), fn=<function Module.cuda.<locals>.<lambda>>)\u001b[0m\n",
            "\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    223\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mparam_applied\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mfn\u001b[0m \u001b[0;34m= <function Module.cuda.<locals>.<lambda> at 0x7f0c61ab4378>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mparam\u001b[0m \u001b[0;34m= Parameter containing:\n",
            "tensor([[ 1.7385e-04,  6.1093e-05, -7.1624e-05,  ...,  8.9739e-05,\n",
            "         -6.6589e-05, -4.2185e-05],\n",
            "        [ 4.3447e-04,  4.6355e-04, -5.5919e-04,  ..., -4.7783e-04,\n",
            "         -1.1129e-04,  3.3581e-04],\n",
            "        [ 7.8919e-05,  6.5069e-04, -3.8269e-04,  ...,  2.0009e-04,\n",
            "         -1.8961e-05, -2.1814e-04],\n",
            "        ...,\n",
            "        [-3.5231e-05, -2.2663e-04, -4.1752e-04,  ...,  2.8889e-04,\n",
            "          3.5028e-04, -8.2401e-06],\n",
            "        [ 1.0547e-04, -5.2049e-04, -7.2306e-05,  ..., -1.0888e-04,\n",
            "         -6.5706e-04,  3.2236e-04],\n",
            "        [-6.8848e-04,  1.4968e-04, -2.0286e-04,  ...,  6.7538e-04,\n",
            "          2.6183e-04, -9.9028e-05]], requires_grad=True)\u001b[0m\n",
            "\u001b[1;32m    225\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t=Parameter containing:\n",
            "tensor([[ 1.7385e-04,  6.1...   2.6183e-04, -9.9028e-05]], requires_grad=True))\u001b[0m\n",
            "\u001b[1;32m    303\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    304\u001b[0m         \"\"\"\n",
            "\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mself._apply\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mt\u001b[0m \u001b[0;34m= Parameter containing:\n",
            "tensor([[ 1.7385e-04,  6.1093e-05, -7.1624e-05,  ...,  8.9739e-05,\n",
            "         -6.6589e-05, -4.2185e-05],\n",
            "        [ 4.3447e-04,  4.6355e-04, -5.5919e-04,  ..., -4.7783e-04,\n",
            "         -1.1129e-04,  3.3581e-04],\n",
            "        [ 7.8919e-05,  6.5069e-04, -3.8269e-04,  ...,  2.0009e-04,\n",
            "         -1.8961e-05, -2.1814e-04],\n",
            "        ...,\n",
            "        [-3.5231e-05, -2.2663e-04, -4.1752e-04,  ...,  2.8889e-04,\n",
            "          3.5028e-04, -8.2401e-06],\n",
            "        [ 1.0547e-04, -5.2049e-04, -7.2306e-05,  ..., -1.0888e-04,\n",
            "         -6.5706e-04,  3.2236e-04],\n",
            "        [-6.8848e-04,  1.4968e-04, -2.0286e-04,  ...,  6.7538e-04,\n",
            "          2.6183e-04, -9.9028e-05]], requires_grad=True)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mt.cuda\u001b[0m \u001b[0;34m= <built-in method cuda of Parameter object at 0x7f0c6b68e4c8>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mdevice\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 8.00 GiB (GPU 0; 15.90 GiB total capacity; 9.17 GiB already allocated; 5.85 GiB free; 186.84 MiB cached)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYdYGziroaq",
        "colab_type": "text"
      },
      "source": [
        "##Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdkwEMkFrv_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Loss\n",
        "a, b = zip(*val_losses)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dshGPo7xXKLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the Accuracy\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Accuracy')\n",
        "a, b = zip(*val_acc)\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ltr9lNr2ag",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGLEzUYIr77s",
        "colab_type": "text"
      },
      "source": [
        "The above CNN architecture achieves...\n",
        "\n",
        "These are the contributions and performance of the model..."
      ]
    }
  ]
}